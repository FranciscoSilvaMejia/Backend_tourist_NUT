{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.  **Instancias** \n",
    "2.  **Query + Filtrado**\n",
    "3.  **Guardado**\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pymongo import MongoClient\n",
    "from shapely.geometry import box,Polygon, Point\n",
    "import datetime\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Instanciamos el mapa y la NUT de estudio\n",
    "\n",
    "Mapas proporcionados por la Unión europea :https://ec.europa.eu/eurostat/web/gisco/geodata/reference-data/administrative-units-statistical-units/nuts\n",
    "\n",
    "Primero instanciamos una bounding box para pedirle al servidor que os devuelva todos los tuits que se hayan hecho en esa localización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUT_ESTUDIO='DE929'                                             #NUT arbitraria de estudio\n",
    "EU_RG= gpd.read_file('mapas\\\\NUTS_RG_10M_2016_4326.shp')\n",
    "\n",
    "Polygon_gpd= EU_RG[EU_RG['NUTS_ID']==NUT_ESTUDIO]['geometry']   #Aquí identificamos la NUT \n",
    "Polygon_sha = Polygon_gpd.iloc[0]                               #Tomamos la clase Polygon de Shapely\n",
    "\n",
    "minx, miny, maxx, maxy= Polygon_sha.bounds                      #Tomamos máximos y mínimos\n",
    "\n",
    "\n",
    "Bbox_json= gpd.GeoSeries([box(minx, miny, maxx, maxy)]).to_json()\n",
    "bbox_dict= eval(Bbox_json)\n",
    "bbox_coords= bbox_dict['features'][0]['geometry']['coordinates']  \n",
    "\n",
    "#Esto úlimo sé que es mucho, pero es para pasar de shp a json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Instanciamos los elementos temporales\n",
    "\n",
    "Para poder limpiar datos vamos a determinar un año de estudio, luego queremos observar como se van desplazando las personas y para ello primero debemos definir su residencia, y posteriormente sus viajes o mudanzas. Se definirá como residencia aquella NUT con mallor número de tweets de un usuario en un mes. \n",
    "\n",
    "Para filtrar bots, y fútiles, vamos a definir unos máximos y mínimos de tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos la ventana de tiempo: yy,mm,dd\n",
    "beg_month= datetime.date(2019,1,1)\n",
    "fin_month= datetime.date(2019,12,1)\n",
    "\n",
    "\n",
    "#Ventana de tiempo de referencia\n",
    "days_before= 30\n",
    "\n",
    "beg_hist_month= beg_month - datetime.timedelta(days=days_before) \n",
    "fin_hist_month= fin_month - datetime.timedelta(days=days_before) \n",
    "\n",
    "#Filtros:\n",
    "max_tweet_in_coll= 1000   #Máximo de tweets registrados en una misma collection\n",
    "max_total_tweets= 1000   #Máximo de tweets totales\n",
    "min_total_tweets= 50     #Cantidad mínima de tweets totales por usuairio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Query + Filtrado\n",
    "\n",
    "Los datos están localizados en diferentes collections, así que deberemos registrarlas una por una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"Direcciión del servidor\"\n",
    "client = MongoClient(host=uri)\n",
    "\n",
    "#Hacemos la conexión correctamente con with\n",
    "with client:\n",
    "    \n",
    "    db = client['twitter'] #Modificación del cliente\n",
    "    uids = set()     #Aquí meteremos todos los ID de los usuarios que han tuiteado en la NUT_ESTUDIO\n",
    "    home_dict=dict() #Aquí almacenaremos el número de usuarios turistas por NUT. EJ: {'DE929':30,'DE732':15 }\n",
    "    \n",
    "    \n",
    "    #-----------------Usuarios en la NUT_ESTUDIO en todas las coll---------------------\n",
    "    \n",
    "    for coll in db.list_collections(): #Debido a que la información está en más de una coll\n",
    "        '''\n",
    "        Aquí pedimos las coordenadas no nulas, que estén dentro de nuestro bbox, que estén en la ventana temporal estipulada.\n",
    "        En cuanto al ID retiramos el del servidor y solicitamos el del usuario.\n",
    "        \n",
    "        '''\n",
    "        doc_geo = coll.find({'coordinates' : {'$ne':  None},\n",
    "                             'coordinates': {'$geoWithin':{'$geometry': {'type' : 'Polygon','coordinates': bbox_coords}}},\n",
    "                             'created_at':{'$gte':beg_month,'$lt': fin_month}}, \n",
    "                            {'_id':0,'user.id':1})\n",
    "        \n",
    "        #Retiramos las repeticiones en general\n",
    "        for user in doc_geo:\n",
    "            uid = user['user']['id']\n",
    "            if uid not in uids:  \n",
    "                uids.add(uid)\n",
    "                \n",
    "    #Con esto obtenemos la lista de usuarios en la NUT de estudio de todas las coll\n",
    "\n",
    "    #------------------------------Selección de turistas------------------------------\n",
    "\n",
    "    for user in uids:\n",
    "        \n",
    "        NUT_user_dict= dict() #Aquí meteremos los lugares donde ha tuiteado un usuario con la misma estructura que home_dict.\n",
    "        \n",
    "        #Buscamos los tweets en todas las coll\n",
    "        for coll in db.list_collections():\n",
    "            \n",
    "            u_rec = coll.find({'user.id': user,\n",
    "                               'created_at':{'$gte':beg_hist_month,'$lt': fin_hist_month}},\n",
    "                              {'_id':0,'coordinates.coordinates': 1}) #'created_at': 1 \n",
    "            \n",
    "            #Filtrado_01\n",
    "            num_doc= u_rec.count()\n",
    "\n",
    "            if  num_doc > max_tweet_in_coll: \n",
    "                continue\n",
    "\n",
    "                \n",
    "            #Recopilamos un 'histograma' con las veces que se repite la NUT\n",
    "            for tweet in u_rec:\n",
    "\n",
    "                coordinates= tweet['coordinates']['coordinates'][0]  #Esto es por el formato json\n",
    "                tweet_point= Point(coordinates[0],coordinates[1])\n",
    "\n",
    "                NUT_point= EU_NUT[EU_NUT.contains(tweet_point)].iloc[0]  #Esto es por como se estructuran los datos del mapa\n",
    "                                                                         #primero saliendo los NUT-3\n",
    "\n",
    "                if NUT_point not in NUT_user_dict:\n",
    "\n",
    "                    NUT_user_dict[NUT_point]= 1\n",
    "\n",
    "                else:\n",
    "                    NUT_user_dict[NUT_point]+= 1\n",
    "                \n",
    "                \n",
    "        #Filtro_02, ahora que tenemos TODOS los tweets de usuario podemos discriminar y tratar los datos\n",
    "        \n",
    "        NUT_u_keys= list(NUT_user_dict.keys())\n",
    "        NUT_u_values= list(NUT_user_dict.values())\n",
    "        \n",
    "        total_tweets= sum(NUT_u_values)\n",
    "        \n",
    "        if total_tweets< min_total_tweets or total_tweets> max_total_tweets: \n",
    "            continue\n",
    "        \n",
    "        if max(NUT_u_values)/total_tweets < 0.7: #pedimos que el 70% de los tweets del mes anterior estén en la misma NUT\n",
    "            continue\n",
    "\n",
    "        #---------------------Evaluamos su home-----------------------\n",
    "\n",
    "        home= NUT_u_keys[NUT_u_values.index(max(NUT_u_values))]\n",
    "\n",
    "        if home != NUT_ESTUDIO:  #Solo guardamos turistas\n",
    "\n",
    "            if home not in home_dict:\n",
    "\n",
    "                home_dict[home]= 1\n",
    "\n",
    "            else:\n",
    "                home_dict[home]+= 1\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras todo el proceso nos quedamos con un diccionario de todos los turistas que han pasado por la región de estudio. Sabiendo de donde vienen y el número, pero se ha perdido la identidad de cada uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Guardado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "with open('turistas_in_mallorca.csv','w') as file:\n",
    "\n",
    "    fieldnames = ['NUT', 'TOURIST_NUMBER']\n",
    "\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    home_key= list(home_dict.keys())\n",
    "    home_value= list(home_dict.values())\n",
    "\n",
    "    for i in range(len(home_key)):\n",
    "\n",
    "        writer.writerow({'NUT': home_key[i], 'NUMBER' : home_value[i]})\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
